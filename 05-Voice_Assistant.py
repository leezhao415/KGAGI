import os
import gradio as gr
import dashscope
import requests
from dashscope.api_entities.dashscope_response import SpeechSynthesisResponse
import pygame
import tempfile
from dotenv import load_dotenv
from tqdm import tqdm

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–DashScopeå®¢æˆ·ç«¯
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")

# å¯ç”¨çš„éŸ³è‰²é€‰é¡¹
VOICE_OPTIONS = {
    "çŸ¥æ€§å¥³å£°(Cherry)": "Cherry",
    "ç”œç¾å¥³å£°(Serena)": "Serena",
    "é˜³å…‰é’å¹´ç”·å£°(Ethan)": "Ethan",
    "ä¼˜é›…å¥³å£°(Chelsie)": "Chelsie"
}


def download_audio_with_progress(url, save_path='output.wav'):
    """
   å¸¦è¿›åº¦æ¡çš„éŸ³é¢‘æ–‡ä»¶ä¸‹è½½
   """
    try:
        response = requests.get(url, stream=True)
        response.raise_for_status()

        # è·å–æ–‡ä»¶æ€»å¤§å°
        total_size = int(response.headers.get('content-length', 0))

        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(os.path.dirname(save_path) if os.path.dirname(save_path) else '.', exist_ok=True)

        # ä¸‹è½½å¹¶æ˜¾ç¤ºè¿›åº¦
        with open(save_path, 'wb') as file, tqdm(
                desc=save_path,
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
        ) as progress_bar:
            for chunk in response.iter_content(chunk_size=512):
                if chunk:
                    size = file.write(chunk)
                    progress_bar.update(size)

        print(f"âœ… éŸ³é¢‘ä¸‹è½½å®Œæˆ: {save_path}")
        return save_path

    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return None


def text_to_speech(text, voice_choice, speed=1.0, pitch=1.0):
    """
    å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³
    
    Args:
        text: è¦è½¬æ¢çš„æ–‡æœ¬
        voice_choice: é€‰æ‹©çš„éŸ³è‰²
        speed: è¯­é€Ÿ (0.5-2.0)
        pitch: éŸ³è°ƒ (0.5-1.5)
    
    Returns:
        ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    if not text.strip():
        return None, "è¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬"

    # è·å–éŸ³è‰²ä»£ç 
    voice_code = VOICE_OPTIONS[voice_choice]

    try:
        # è°ƒç”¨DashScope TTS API
        response = dashscope.audio.qwen_tts.SpeechSynthesizer.call(
            model='qwen-tts',
            text=text,
            voice=voice_code,
            rate=speed,
            pitch=pitch
        )
        audio_url = response.output.audio["url"]

        if not audio_url:
            print("é”™è¯¯ï¼šåœ¨å“åº”ä¸­æœªæ‰¾åˆ°éŸ³é¢‘URL")
            return False

        # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
        print("æ­£åœ¨ä¸‹è½½éŸ³é¢‘æ–‡ä»¶...")
        save_path = download_audio_with_progress(audio_url)

        if response.status_code == 200:
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            return save_path, "è¯­éŸ³åˆæˆæˆåŠŸ"
        else:
            print(f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return None

    except Exception as e:
        return None, f"è¯­éŸ³åˆæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"


# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="æ˜Ÿç¿è¯­éŸ³åŠ©æ‰‹") as demo:
    gr.Markdown("# ğŸŒŸæ˜Ÿç¿è¯­éŸ³åŠ©æ‰‹")
    gr.Markdown("å°†æ–‡å­—è½¬æ¢ä¸ºè‡ªç„¶è¯­éŸ³ï¼Œæ”¯æŒå¤šç§éŸ³è‰²é€‰æ‹©")

    with gr.Row():
        with gr.Column():
            text_input = gr.TextArea(
                label="è¾“å…¥æ–‡æœ¬",
                placeholder="è¯·è¾“å…¥è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡æœ¬...",
                lines=5
            )

            with gr.Row():
                voice_choice = gr.Dropdown(
                    choices=list(VOICE_OPTIONS.keys()),
                    value="çŸ¥æ€§å¥³å£°(Cherry)",
                    label="éŸ³è‰²é€‰æ‹©"
                )

                speed = gr.Slider(
                    minimum=0.5,
                    maximum=2.0,
                    value=1.0,
                    step=0.1,
                    label="è¯­é€Ÿ"
                )

                pitch = gr.Slider(
                    minimum=0.5,
                    maximum=1.5,
                    value=1.0,
                    step=0.1,
                    label="éŸ³è°ƒ"
                )

            convert_btn = gr.Button("ç”Ÿæˆè¯­éŸ³", variant="primary")

        with gr.Column():
            audio_output = gr.Audio(
                label="ç”Ÿæˆçš„è¯­éŸ³",
                type="filepath"
            )
            status_output = gr.Textbox(
                label="çŠ¶æ€ä¿¡æ¯"
            )

    # è®¾ç½®äº‹ä»¶å¤„ç†
    convert_btn.click(
        fn=text_to_speech,
        inputs=[text_input, voice_choice, speed, pitch],
        outputs=[audio_output, status_output]
    )

    gr.Markdown("---")
    gr.Markdown("### ä½¿ç”¨è¯´æ˜")
    gr.Markdown("""
    1. åœ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡å­—
    2. é€‰æ‹©å–œæ¬¢çš„éŸ³è‰²å’Œè¯­é€Ÿã€éŸ³è°ƒå‚æ•°
    3. ç‚¹å‡»"ç”Ÿæˆè¯­éŸ³"æŒ‰é’®
    4. ç­‰å¾…è¯­éŸ³ç”Ÿæˆå®Œæˆåå¯ç›´æ¥æ’­æ”¾
    """)

if __name__ == "__main__":
    demo.launch(server_name="127.0.0.1", server_port=7860)
